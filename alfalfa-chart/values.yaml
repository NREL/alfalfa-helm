# Default values for alfalfa.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

secret:
  name: "aws-secrets"

env:
  public:
    JOB_QUEUE_URL: http://goaws:4100/queue/local-queue1
    JOB_QUEUE_URL_1: http://goaws:4100/queue/local-queue1
    JOB_QUEUE_URL_2: http://goaws:4100/queue/local-queue2
    MONGO_URL: mongodb://mongo:27017
    MONGO_DB_NAME: alfalfa
    LOGLEVEL: DEBUG
    NODE_ENV: production
    S3_URL: http://minio
    #S3_URL_EXTERNAL: https://alfalfa-cbri.nrel.gov 
    #AWS S3 end point url example below. See docs on obtaining url using kubectl 
    S3_URL_EXTERNAL: http://a767c1335c88545b6955157e38eabd0c-1443732694.us-west-2.elb.amazonaws.com:9000
    REDIS_HOST: redis
    S3_BUCKET: alfalfa
    REGION: us-west-1
    INFLUXDB_DB: alfalfa
    INFLUXDB_HOST: influxdb
    # Need to start influx with this disabled first and then 
    # can set to true
    INFLUXDB_HTTP_AUTH_ENABLED: false
    HISTORIAN_ENABLE: true

  private:
    AWS_ACCESS_KEY_ID: user
    AWS_SECRET_ACCESS_KEY: password
    INFLUXDB_ADMIN_USER: admin
    INFLUXDB_ADMIN_PASSWORD: password
    GF_SECURITY_ADMIN_PASSWORD: password
    GF_SECURITY_ADMIN_USER: admin

# Set to google, aws, azure or docker-local
# docker-local is the docker-desktop and used for local deployments
provider: 
  name: "aws"

# Specifc values for rancher deployments only
rancher:
  hostnames:
    minio: "alfalfa-cbri.nrel.gov"
    web: "alfalfa.nrel.gov"
    grafana: "grafana-cbri.nrel.gov"

domain_name: "localhost"

nginx_https:
  name: "nginx-https"
  enable: false
  domain_name: "localhost"

tags:
  log_stack: false

cluster:
  name: "alfalfa" 

# rancher uses netappnfs for storageClass
storageClass: "ssd"

mongo:
  name:  "mongo"
  label: "mongo"
  container:
    name: "mongo"
    image: "mongo"
    resources:
      limits:
        cpu: 0.5
        memory: "1Gi"
      requests:
        cpu: 0.25
        memory: "512Mi"
    ports:
      db_port: 27017
  persistence:
    enabled: true
    size: 10Gi
    accessModes:
      - "ReadWriteOnce"

influxdb:
  name:  "influxdb"
  label: "influxdb"
  container:
    name: "influxdb"
    image: "influxdb:1.8"
    resources:
      limits:
        cpu: 1
        memory: "2Gi"
      requests:
        cpu: 0.5
        memory: "1G"
    ports:
      db_port: 8086
  persistence:
    enabled: true
    size: 10Gi
    accessModes:
      - "ReadWriteOnce"

grafana:
  name:  "grafana"
  ingress_host: "grafana-cbri.nrel.gov"
  label: "grafana"
  container:
    name: "grafana"
    image: "grafana/grafana:8.5.4"
    resources:
      limits:
        cpu: 1
        memory: "2Gi"
      requests:
        cpu: 0.5
        memory: "1G"
    ports:
      grafana_port: 3000

certbot:
  name:  "certbot"
  label: "certbot"
  container:
    name: "certbot"
    image: "certbot/certbot"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"
  persistence:
    enabled: true
    size: 1Gi
    accessModes:
      - "ReadWriteOnce"

load_balancer:
  name: "ingress-load-balancer"
  externalTrafficPolicy: "Local"
  label: "nginx-ingress"
  ports:
    http_name: "http" 
    http_port: 80
    http_protocol: "TCP"
    http_test_name: "http-test" 
    http_test_port: 29043
    http_test_protocol: "TCP"
    https_name: "https"
    https_port: 443
    https_protocol: "TCP"
    sns_name: "sns" 
    sns_port: 9000
    sns_protocol: "TCP"
    kibana_name: "kibana"
    kibana_port: 5601
    kibana_protocol: "TCP"
    dashboard_name: "dashboard"
    dashboard_port: 8081
    dashboard_protocol: "TCP"
  loadBalancerSourceRanges: 0.0.0.0/0

nginx_ingress:
  name: "nginx-ingress"
  label: "nginx-ingress"
  container:
    name: "nginx-ingress"
    image: "nginx:1.17.8"
    resources:
      limits:
        cpu: 0.25
        memory: "1Gi"
      requests:
        cpu: 0.1
        memory: "256Mi"

redis:
  name: "redis"
  label: "redis"
  container:
    name: "redis"
    image: "redis:4.0.6"
    resources:
      limits:
        cpu: 1
        memory: "2Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    ports:
      redis: 6379

goaws:
  name: "goaws"
  label: "goaws"
  container:
    name: "goaws"
    image: "pafortin/goaws"
    resources:
      limits:
        cpu: 0.5
        memory: "512Mi"
      requests:
        cpu: 0.25
        memory: "256Mi"
    ports:
      sns: 4100

minio:
  name: "minio"
  label: "minio"
  container:
    name: "minio"
    image: "minio/minio"
    resources:
      limits:
        cpu: 0.5
        memory: "1Gi"
      requests:
        cpu: 0.25
        memory: "256Mi"
    ports:
      s3: 9000
      web: 80
  persistence:
    enabled: true
    size: 10Gi
    accessModes:
      - "ReadWriteOnce"

mc:
  name: "mc"
  label: "mc"
  container:
    name: "mc"
    image: "minio/mc"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"
    ports:
      s3: 9000

web:
  name: "web"
  label: "web"
  container:
    name: "web"
    image: "nrel/alfalfa-web:0.4.0"
    resources:
      limits:
        cpu: 1
        memory: "3Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    ports:
      http: 80
      test: 29043

nginx_dashboard:
  name: "nginx-dashboard"
  label: "nginx-dashboard"
  container:
    name: "nginx-dashboard"
    image: "nginx:1.17.8"
    resources:
      limits:
        cpu: 0.25
        memory: "1Gi"
      requests:
        cpu: 0.1
        memory: "256Mi"
    ports:
      http: 8081

worker:
  name: "worker" 
  label: "worker" 
  replicas: 2
  container:
    name: "worker"
    image: "nrel/alfalfa-worker:0.4.0"
    resources:
      limits:
        cpu: 1
        memory: "4Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    terminationGracePeriodSeconds: 3600


elastic_job:
  name: "elastic-job"
  label: "elastic-job"
  container:
    name: "elastic-job"
    image: "elasticdump/elasticsearch-dump"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"

elasticsearch:
   resources:
     requests:
       cpu: "1000m"
       memory: "512Mi"
     limits:
       cpu: "1000m"
       memory: "2Gi"
   replicas: 1
   minimumMasterNodes: 1
   # https://github.com/elastic/helm-charts/issues/783
   clusterHealthCheckParams: 'wait_for_status=yellow&timeout=1s'
   persistence:
     enabled: false
   esConfig:
     elasticsearch.yml: |
       xpack.security.enabled: false
       ingest.geoip.downloader.enabled: false


filebeat:
  managedServiceAccount: false
  extraVolumeMounts: 
    - name: varlibdockeroverlay2
      mountPath: /var/lib/docker/overlay2
      readOnly: true
  extraVolumes: 
    - hostPath:
        path: /var/lib/docker/overlay2
      name: varlibdockeroverlay2
  resources:
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "1000m"
      memory: "2000Mi"
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
      - type: container
        paths:
          - /var/log/containers/*.log
        processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
      - type: filestream
        scan_frequency: 60s
        paths:
          - /var/lib/docker/overlay2/*/diff/simulate/**/*
        prospector.scanner.include_files: ['.*\.log', '.*\.err']
        processors:
          - dissect:
              tokenizer: "%{}/diff/%{filepath}"
              field: "log.file.path"
              target_prefix: "simlog"
          - dissect:
              tokenizer: "%{}/diff/simulate/%{id}/%{}"
              field: "log.file.path"
              target_prefix: "simlog"
      output.elasticsearch:
        host: '${NODE_NAME}'
        hosts: '${ELASTICSEARCH_HOSTS:elasticsearch-master:9200}'
