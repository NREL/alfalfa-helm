# Default values for alfalfa.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

secret:
  name: "aws-secrets"

env:
  public:
    JOB_QUEUE: Alfalfa Job Queue
    MONGO_URL: mongodb://mongo:27017
    MONGO_DB_NAME: alfalfa
    LOGLEVEL: DEBUG
    NODE_ENV: production
    S3_URL: http://minio
    S3_URL_EXTERNAL: https://alfalfa-cbri.nrel.gov
    #AWS S3 end point url example below. See docs on obtaining url using kubectl
    # S3_URL_EXTERNAL: http://a767c1335c88545b6955157e38eabd0c-1443732694.us-west-2.elb.amazonaws.com:9000
    REDIS_HOST: redis
    S3_BUCKET: alfalfa
    REGION: us-west-1
    INFLUXDB_DB: alfalfa
    INFLUXDB_HOST: influxdb
    # Need to start influx with this disabled first and then
    # can set to true
    INFLUXDB_HTTP_AUTH_ENABLED: false
    HISTORIAN_ENABLE: false

  private:
    AWS_ACCESS_KEY_ID: user
    AWS_SECRET_ACCESS_KEY: password
    INFLUXDB_ADMIN_USER: admin
    INFLUXDB_ADMIN_PASSWORD: password
    GF_SECURITY_ADMIN_PASSWORD: password
    GF_SECURITY_ADMIN_USER: admin

# Set to google, aws, azure or docker-local
# docker-local is the docker-desktop and used for local deployments
provider:
  name: "aws"

# Specifc values for rancher deployments only
rancher:
  hostnames:
    minio: "alfalfa-cbri.nrel.gov"
    web: "alfalfa.nrel.gov"
    grafana: "grafana-cbri.nrel.gov"

domain_name: "localhost"

nginx_https:
  name: "nginx-https"
  enable: false
  domain_name: "localhost"

tags:
  log_stack: false

cluster:
  name: "alfalfa"

# rancher uses netappnfs for storageClass
storageClass: "ssd"

mongo:
  name:  "mongo"
  label: "mongo"
  container:
    name: "mongo"
    image: "mongo:5.0.14"
    resources:
      limits:
        cpu: 0.5
        memory: "1Gi"
      requests:
        cpu: 0.25
        memory: "512Mi"
    ports:
      db_port: 27017
  persistence:
    enabled: true
    size: 10Gi
    accessModes:
      - "ReadWriteOnce"

influxdb:
  name:  "influxdb"
  label: "influxdb"
  container:
    name: "influxdb"
    image: "influxdb:1.8"
    resources:
      limits:
        cpu: 1
        memory: "2Gi"
      requests:
        cpu: 0.5
        memory: "1G"
    ports:
      db_port: 8086
  persistence:
    enabled: true
    size: 10Gi
    accessModes:
      - "ReadWriteOnce"

grafana:
  name:  "grafana"
  ingress_host: "grafana-cbri.nrel.gov"
  label: "grafana"
  container:
    name: "grafana"
    image: "ghcr.io/nrel/alfalfa/grafana:0.7.0"
    resources:
      limits:
        cpu: 1
        memory: "2Gi"
      requests:
        cpu: 0.5
        memory: "1G"
    ports:
      grafana_port: 3000

certbot:
  name:  "certbot"
  label: "certbot"
  container:
    name: "certbot"
    image: "certbot/certbot"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"
  persistence:
    enabled: true
    size: 1Gi
    accessModes:
      - "ReadWriteOnce"

load_balancer:
  name: "ingress-load-balancer"
  externalTrafficPolicy: "Local"
  label: "nginx-ingress"
  ports:
    http_name: "http"
    http_port: 80
    http_protocol: "TCP"
    http_test_name: "http-test"
    http_test_port: 29043
    http_test_protocol: "TCP"
    https_name: "https"
    https_port: 443
    https_protocol: "TCP"
    sns_name: "sns"
    sns_port: 9000
    sns_protocol: "TCP"
    kibana_name: "kibana"
    kibana_port: 5601
    kibana_protocol: "TCP"
    dashboard_name: "dashboard"
    dashboard_port: 8081
    dashboard_protocol: "TCP"
  loadBalancerSourceRanges: 0.0.0.0/0

nginx_ingress:
  name: "nginx-ingress"
  label: "nginx-ingress"
  container:
    name: "nginx-ingress"
    image: "nginx:1.17.8"
    resources:
      limits:
        cpu: 0.25
        memory: "1Gi"
      requests:
        cpu: 0.1
        memory: "256Mi"

redis:
  name: "redis"
  label: "redis"
  container:
    name: "redis"
    image: "redis:7.0.7"
    resources:
      limits:
        cpu: 1
        memory: "2Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    ports:
      redis: 6379

minio:
  name: "minio"
  label: "minio"
  container:
    name: "minio"
    image: "minio/minio:RELEASE.2021-01-16T02-19-44Z"
    resources:
      limits:
        cpu: 0.5
        memory: "1Gi"
      requests:
        cpu: 0.25
        memory: "256Mi"
    ports:
      s3: 9000
      web: 80
  persistence:
    enabled: true
    size: 10Gi
    accessModes:
      - "ReadWriteOnce"

mc:
  name: "mc"
  label: "mc"
  container:
    name: "mc"
    image: "minio/mc:RELEASE.2022-12-13T00-23-28Z"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"
    ports:
      s3: 9000

web:
  name: "web"
  label: "web"
  container:
    name: "web"
    image: "ghcr.io/nrel/alfalfa/web:0.7.0"
    resources:
      limits:
        cpu: 1
        memory: "3Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    ports:
      http: 80
      test: 29043

nginx_dashboard:
  name: "nginx-dashboard"
  label: "nginx-dashboard"
  container:
    name: "nginx-dashboard"
    image: "nginx:1.17.8"
    resources:
      limits:
        cpu: 0.25
        memory: "1Gi"
      requests:
        cpu: 0.1
        memory: "256Mi"
    ports:
      http: 8081

worker:
  name: "worker"
  label: "worker"
  replicas: 5
  container:
    name: "worker"
    image: "ghcr.io/nrel/alfalfa/worker:0.7.0"
    resources:
      limits:
        cpu: 1
        memory: "4Gi"
      requests:
        cpu: 0.5
        memory: "1Gi"
    terminationGracePeriodSeconds: 3600


elastic_job:
  name: "elastic-job"
  label: "elastic-job"
  container:
    name: "elastic-job"
    image: "elasticdump/elasticsearch-dump"
    resources:
      limits:
        cpu: 0.25
        memory: "512Mi"
      requests:
        cpu: 0.1
        memory: "256Mi"

elasticsearch:
   resources:
     requests:
       cpu: "1000m"
       memory: "512Mi"
     limits:
       cpu: "1000m"
       memory: "2Gi"
   replicas: 1
   minimumMasterNodes: 1
   # https://github.com/elastic/helm-charts/issues/783
   clusterHealthCheckParams: 'wait_for_status=yellow&timeout=1s'
   persistence:
     enabled: false
   esConfig:
     elasticsearch.yml: |
       xpack.security.enabled: false
       ingest.geoip.downloader.enabled: false


filebeat:
  managedServiceAccount: false
  extraVolumeMounts:
    - name: varlibdockeroverlay2
      mountPath: /var/lib/docker/overlay2
      readOnly: true
  extraVolumes:
    - hostPath:
        path: /var/lib/docker/overlay2
      name: varlibdockeroverlay2
  resources:
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "1000m"
      memory: "2000Mi"
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
      - type: container
        paths:
          - /var/log/containers/*.log
        processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
      - type: filestream
        scan_frequency: 60s
        paths:
          - /var/lib/docker/overlay2/*/diff/simulate/**/*
        prospector.scanner.include_files: ['.*\.log', '.*\.err']
        processors:
          - dissect:
              tokenizer: "%{}/diff/%{filepath}"
              field: "log.file.path"
              target_prefix: "simlog"
          - dissect:
              tokenizer: "%{}/diff/simulate/%{id}/%{}"
              field: "log.file.path"
              target_prefix: "simlog"
      output.elasticsearch:
        host: '${NODE_NAME}'
        hosts: '${ELASTICSEARCH_HOSTS:elasticsearch-master:9200}'
